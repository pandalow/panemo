{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dataset.dataloader import EmoDataset\n",
    "from models.model import MyEmoSubword\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 假设我们用一个 dict 来存所有参数\n",
    "    args = {\n",
    "        'model_path': 'meta-llama/Llama-3.1-8B',\n",
    "        'file_path': 'data/eng/train.csv',\n",
    "        'lang': 'en',\n",
    "        'max_len': 128,\n",
    "        'num_labels': 5,\n",
    "        'dropout': 0.1,\n",
    "        'joint_loss': 'joint',\n",
    "        'alpha': 0.2,\n",
    "        'pool_type': 'mean'\n",
    "    }\n",
    "\n",
    "    # 构建 Dataset\n",
    "    dataset = EmoDataset(args)\n",
    "    batch_size = 4\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "\n",
    "    # 构建 Model\n",
    "    model = MyEmoSubword(args)\n",
    "    model.to(device)\n",
    "\n",
    "    # 简单的训练循环\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "    model.train()\n",
    "    for epoch in range(3):\n",
    "        for batch in dataloader:\n",
    "            input_ids, labels, label_positions = batch\n",
    "\n",
    "            # 把数据移动到 MPS\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            label_positions = label_positions.to(device)\n",
    "\n",
    "            # Forward\n",
    "            loss, bsz, preds, golds = model((input_ids, labels, label_positions))\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_of_text|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuangxiaojian/Documents/research/panemo/dataset/dataloader.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  all_labels = torch.tensor(all_labels, dtype=torch.float)                              # [dataset_size, num_labels]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Downloading shards: 100%|██████████| 4/4 [07:11<00:00, 107.91s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [01:07<01:10, 35.25s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
